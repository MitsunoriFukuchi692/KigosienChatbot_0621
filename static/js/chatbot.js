// static/js/chatbot.js
console.log('chatbot.js loaded');

// â”€â”€â”€ TTS ã‚¢ãƒ³ãƒ­ãƒƒã‚¯ â”€â”€â”€
window.addEventListener('click', function _unlockTTS() {
  if ('speechSynthesis' in window) {
    window.speechSynthesis.speak(new SpeechSynthesisUtterance(''));
  }
  window.removeEventListener('click', _unlockTTS);
});
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// è¦ç´ å–å¾—ï¼ˆdefer ã«ã‚ˆã‚Š DOM æ§‹ç¯‰æ¸ˆï¼‰
const chatContainer    = document.getElementById('chat-container');
const templates        = document.querySelectorAll('#template-container button');
const inpCaregiver     = document.getElementById('caregiver-input');
const inpElder         = document.getElementById('elder-input');
const btnCaregiverSend = document.getElementById('caregiver-send');
const btnElderSend     = document.getElementById('elder-send');
const selMicRole       = document.getElementById('mic-role');
const btnMicStart      = document.getElementById('mic-start');
const btnDownloadCsv   = document.getElementById('download-csv');
const ttsPlayer        = document.getElementById('tts-player');
const volControl       = document.getElementById('volume');
const chkSlow          = document.getElementById('slow-playback');

const apiPath = '/chat';
let recognition, currentMicRole = 'caregiver';
let conversation = [];
let currentLang = new URLSearchParams(location.search).get('lang') || 'ja';

console.log('Initializing chatbotâ€¦');

// ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒœã‚¿ãƒ³
templates.forEach(btn => btn.addEventListener('click', () => {
  console.log('template clicked:', btn.dataset.cat);
  const cat = btn.dataset.cat;
  appendMessage('caregiver', btn.textContent);
  logConversation('caregiver', btn.textContent);
  inpElder.value = '';
  inpElder.focus();
  if (cat === 'èª¬æ˜') {
    const term = prompt('èª¬æ˜ã—ã¦ã»ã—ã„ç”¨èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„');
    if (term) callAIExplain(term);
  }
}));

// ä»‹è­·å£«é€ä¿¡
btnCaregiverSend.addEventListener('click', () => {
  console.log('ğŸ‘©â€âš•ï¸ caregiver-send clicked');
  const text = inpCaregiver.value.trim(); if (!text) return;
  appendMessage('caregiver', text);
  logConversation('caregiver', text);
  // TTSã§èª­ã¿ä¸Šã’
  console.log('ğŸ”Š play caregiver message:', text);
  playTTS(text);
  inpCaregiver.value = '';
  inpElder.focus();
});

// è¢«ä»‹è­·è€…é€ä¿¡
btnElderSend.addEventListener('click', () => {
  console.log('ğŸ‘µ elder-send clicked');
  const text = inpElder.value.trim(); if (!text) return;
  appendMessage('elder', text);
  logConversation('elder', text);
  // TTSã§èª­ã¿ä¸Šã’
  console.log('ğŸ”Š play elder message:', text);
  playTTS(text);
  inpElder.value = '';
});

// ä»¥é™åŒã˜('click', () => {
  console.log('ğŸ‘µ elder-send clicked');
  const text = inpElder.value.trim(); if (!text) return;
  appendMessage('elder', text);
  logConversation('elder', text);
  inpElder.value = '';
});

// ãƒã‚¤ã‚¯å…¥åŠ›è¨­å®š
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
if (SpeechRecognition) {
  console.log('ğŸ™ SpeechRecognition API is available');
  recognition = new SpeechRecognition();
  recognition.lang = currentLang === 'ja' ? 'ja-JP' : 'en-US';
  recognition.interimResults = false;
  recognition.onstart = () => console.log('ğŸ™ recognition.onstart');
  recognition.onerror = e => console.error('ğŸ™ recognition.onerror', e);
  recognition.onend = () => console.log('ğŸ™ recognition.onend');
  recognition.onresult = e => {
    const text = e.results[0][0].transcript;
    console.log('ğŸ™ recognition.onresult:', text);
    appendMessage(currentMicRole, text);
    logConversation(currentMicRole, text);
    if (currentMicRole === 'elder') inpElder.value = '';
  };
  btnMicStart.addEventListener('click', () => {
    console.log('ğŸ™ btnMicStart clicked, calling recognition.start()');
    recognition.start();
  });
} else {
  console.warn('SpeechRecognition not supported');
  btnMicStart.disabled = true;
}
selMicRole.addEventListener('change', () => {
  console.log('mic-role changed to', selMicRole.value);
  currentMicRole = selMicRole.value;
});

// CSVä¿å­˜
btnDownloadCsv.addEventListener('click', () => {
  console.log('ğŸ’¾ CSVä¿å­˜ clicked');
  const rows = [['role','message','timestamp'], ...conversation.map(c => [c.role, c.message, c.timestamp])];
  const blob = new Blob([rows.map(r => r.join(',')).join('
')], { type: 'text/csv' });
  const a = document.createElement('a');
  a.href = URL.createObjectURL(blob);
  a.download = 'conversation_log.csv';
  a.click();
  URL.revokeObjectURL(a.href);
});

// ç”¨èªèª¬æ˜ï¼ˆAI å‘¼ã³å‡ºã—ï¼‰
function callAIExplain(term) {
  console.log('â–¶ send to chat:', term);
  fetch(`${apiPath}?lang=${currentLang}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ role: 'explain', message: term })
  })
  .then(res => {
    console.log('â—€ response status:', res.status);
    return res.json();
  })
  .then(data => {
    console.log('â—€ data.reply:', data.reply);
    appendMessage('bot', data.reply);
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ audio è¦ç´ ã‚’ä½¿ã£ã¦å†ç”Ÿ
    console.log('ğŸ”Š playTTS via audio element:', data.reply);
    const url = `/tts?text=${encodeURIComponent(data.reply)}&slow=${chkSlow.checked ? 1 : 0}`;
    ttsPlayer.src = url;
    ttsPlayer.volume = +volControl.value;
    ttsPlayer.play().catch(err => console.error('Audio playback error:', err));
    logConversation('bot', data.reply);
  })
  .catch(err => console.error('fetch error:', err));
}

// ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
function appendMessage(role, text) {
  const d = document.createElement('div');
  d.className = `message ${role}`;
  const p = role === 'caregiver' ? 'ğŸ‘©â€âš•ï¸ ' : role === 'elder' ? 'ğŸ‘µ ' : 'ğŸ¤– ';
  d.textContent = p + text;
  chatContainer.appendChild(d);
  chatContainer.scrollTop = chatContainer.scrollHeight;
}

// ä¼šè©±ãƒ­ã‚°è¨˜éŒ²
function logConversation(role, message) {
  conversation.push({ role, message, timestamp: new Date().toISOString() });
}
